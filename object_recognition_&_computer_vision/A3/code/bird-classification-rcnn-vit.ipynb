{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook example using Kaggle GPU","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, utils\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\n\n\nfrom tqdm import tqdm\nimport PIL.Image as Image\n\nif not os.path.isdir('./experiments'):\n    os.makedirs('./experiments')\n    \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T17:30:57.147898Z","iopub.execute_input":"2021-11-22T17:30:57.148256Z","iopub.status.idle":"2021-11-22T17:30:57.156336Z","shell.execute_reply.started":"2021-11-22T17:30:57.148213Z","shell.execute_reply":"2021-11-22T17:30:57.155361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detection\n\nskip this for training ViT","metadata":{}},{"cell_type":"code","source":"detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\ndetector = detector.to(device)\ndetector.eval()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:30:57.158237Z","iopub.execute_input":"2021-11-22T17:30:57.159038Z","iopub.status.idle":"2021-11-22T17:30:58.034104Z","shell.execute_reply.started":"2021-11-22T17:30:57.159Z","shell.execute_reply":"2021-11-22T17:30:58.033188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r ./bird_dataset_cropped","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:30:58.037814Z","iopub.execute_input":"2021-11-22T17:30:58.038102Z","iopub.status.idle":"2021-11-22T17:30:58.853049Z","shell.execute_reply.started":"2021-11-22T17:30:58.038062Z","shell.execute_reply":"2021-11-22T17:30:58.852029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/mva-recvis-2021/bird_dataset ./bird_dataset_cropped","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:30:58.857618Z","iopub.execute_input":"2021-11-22T17:30:58.857855Z","iopub.status.idle":"2021-11-22T17:31:00.84773Z","shell.execute_reply.started":"2021-11-22T17:30:58.857826Z","shell.execute_reply":"2021-11-22T17:31:00.846684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder('./bird_dataset_cropped/train_images')\nval_dataset = datasets.ImageFolder('./bird_dataset_cropped/val_images')\ntest_dataset = datasets.ImageFolder('./bird_dataset_cropped/test_images')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:31:00.849657Z","iopub.execute_input":"2021-11-22T17:31:00.850038Z","iopub.status.idle":"2021-11-22T17:31:00.869654Z","shell.execute_reply.started":"2021-11-22T17:31:00.849979Z","shell.execute_reply":"2021-11-22T17:31:00.868934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(tensor):\n    img = tensor.permute(1, 2, 0).numpy()\n    plt.imshow(img)\n\ndef crop_bird(img_tensor):\n    '''\n    For each image (3xHxW), detect bounding box of bird with highest proba and crop\n    '''\n    data = img_tensor.to(device).unsqueeze(0)\n    out = detector(data)[0]\n    \n    boxes, labels, scores = out['boxes'], out['labels'], out['scores']\n    boxes = boxes[labels==16]\n    scores = scores[labels==16]  \n    \n#     n = boxes.size(0)\n#     visual = utils.draw_bounding_boxes(torch.tensor(img.detach().cpu()*255, dtype=torch.uint8), out['boxes'], colors=[(int(x), int(x), int(x)) for x in (np.arange(n)/n*255)])\n#     imshow(visual)\n    \n    x1, y1, x2, y2 = boxes[scores.argmax()]\n    return img_tensor[:, int(y1):int(y2), int(x1):int(x2)].detach().cpu()\n    \nfor dataset in [train_dataset, val_dataset, test_dataset]:\n    for i in tqdm(np.arange(len(dataset))):\n        path = dataset.imgs[i][0]\n#         print('cropping' , path)\n        img = transforms.ToTensor()(dataset[i][0])\n        try:\n            cropped = crop_bird(img)\n            plt.imsave(path, cropped.permute(1, 2, 0).numpy())\n        except:\n            imshow(img)\n            print('Cannot crop image ', path)\n            continue\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:31:00.870967Z","iopub.execute_input":"2021-11-22T17:31:00.871352Z","iopub.status.idle":"2021-11-22T17:33:19.050679Z","shell.execute_reply.started":"2021-11-22T17:31:00.871296Z","shell.execute_reply":"2021-11-22T17:33:19.049984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('./bird_dataset_cropped', 'zip', './bird_dataset_cropped')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:19.051914Z","iopub.execute_input":"2021-11-22T17:33:19.052273Z","iopub.status.idle":"2021-11-22T17:33:19.680705Z","shell.execute_reply.started":"2021-11-22T17:33:19.052234Z","shell.execute_reply":"2021-11-22T17:33:19.679962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model + optimizer","metadata":{}},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n    transforms.Resize((224, 224), Image.BILINEAR),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224), Image.BILINEAR),\n#     transforms.RandomRotation(15),\n#     transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize    \n])\n\nvalid_transforms = transforms.Compose([\n    transforms.Resize((224, 224), Image.BILINEAR),\n#     transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize,\n])\n\nbatch_size = 16\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/bird-dataset-cropped/bird_dataset_cropped/train_images', transform=train_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/bird-dataset-cropped/bird_dataset_cropped/val_images',transform=valid_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/bird-dataset-cropped/bird_dataset_cropped/test_images',transform=valid_transforms),\n    batch_size=1, shuffle=False, num_workers=1)\n\ntrain_size, val_size = len(train_loader.dataset), len(val_loader.dataset)\nprint(train_size, val_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:19.682143Z","iopub.execute_input":"2021-11-22T17:33:19.682391Z","iopub.status.idle":"2021-11-22T17:33:20.222872Z","shell.execute_reply.started":"2021-11-22T17:33:19.682358Z","shell.execute_reply":"2021-11-22T17:33:20.222156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install timm\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:20.224219Z","iopub.execute_input":"2021-11-22T17:33:20.22461Z","iopub.status.idle":"2021-11-22T17:33:34.731377Z","shell.execute_reply.started":"2021-11-22T17:33:20.224575Z","shell.execute_reply":"2021-11-22T17:33:34.730599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n\n\nfor f in os.listdir('experiments/'):\n    os.remove(os.path.join('experiments', f))\n\n\n\n# model_name = 'resnet152'\n# model_name = 'vgg19_bn'\n# model_name = 'efficientnet_b7'\n# model_name = 'resnext'\nmodel_name = 'vit'\n\nif model_name == 'resnet152':\n    model = torchvision.models.resnet152(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n    model.fc = nn.Linear(model.fc.in_features, 20)\n\nif model_name == 'vgg19_bn':\n    model = torchvision.models.vgg19_bn(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    for l in model.classifier.parameters():\n        param.requires_grad = True\n    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 20)\n\nif model_name == 'efficientnet_b7':\n    model = torchvision.models.efficientnet_b7(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 20)\n\nif model_name == 'resnext':\n    model = torchvision.models.resnext101_32x8d(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n    model.fc = nn.Linear(model.fc.in_features, 20)\n    \nif model_name == 'vit':\n    model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=20)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.blocks[-1].parameters():\n        param.requires_grad = True\n    model.head = nn.Linear(model.head.in_features, 20)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:34.734261Z","iopub.execute_input":"2021-11-22T17:33:34.734526Z","iopub.status.idle":"2021-11-22T17:33:45.440512Z","shell.execute_reply.started":"2021-11-22T17:33:34.734492Z","shell.execute_reply":"2021-11-22T17:33:45.43961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5, weight_decay=0.1)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, min_lr=1e-8, patience=5)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:45.441915Z","iopub.execute_input":"2021-11-22T17:33:45.442193Z","iopub.status.idle":"2021-11-22T17:33:45.539656Z","shell.execute_reply.started":"2021-11-22T17:33:45.442154Z","shell.execute_reply":"2021-11-22T17:33:45.538862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, epoch):\n    model.train()\n    training_loss = 0\n    correct = 0\n    \n    for batch_idx, (data, labels) in enumerate(train_loader):\n               \n        data, labels = data.to(device), labels.to(device)\n        optimizer.zero_grad()\n        \n        #forward\n        preds = model(data)\n        loss = criterion(preds, labels)\n        \n        training_loss += loss.data.cpu().item()*len(data)\n        loss.backward()\n        optimizer.step()\n        \n        probs = F.softmax(preds, dim=1)\n        preds_classes = probs.max(1)[1]\n        correct += (preds_classes == labels).sum().data.cpu().detach().item()\n        \n        if batch_idx % 25 == 0:\n            print('[{:4d}/{:4d} ({:2.0f}%)]\\tLoss: {:.4f}'.format(\n                batch_idx * batch_size, train_size,\n                100. * batch_idx * batch_size / train_size, loss.data.cpu().detach().item()))\n    \n    return training_loss / train_size, correct / train_size\n\n\ndef validation(model):\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    \n    with torch.no_grad():\n        for data, labels in val_loader:\n            data, labels = data.to(device), labels.to(device)\n            preds = model(data)\n            \n            # sum up batch loss\n            validation_loss += criterion(preds, labels).data.cpu().detach().item()*len(data)\n            probs = F.softmax(preds, dim=1)\n            preds_classes = probs.max(1)[1]\n            correct += (preds_classes == labels).sum().data.cpu().detach().item()\n            \n    return validation_loss / val_size, correct / val_size\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:45.541155Z","iopub.execute_input":"2021-11-22T17:33:45.541435Z","iopub.status.idle":"2021-11-22T17:33:45.705681Z","shell.execute_reply.started":"2021-11-22T17:33:45.541399Z","shell.execute_reply":"2021-11-22T17:33:45.704555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 25\ntraining_losses = []\ntraining_accs = []\nvalidation_losses = []\nvalidation_accs = []\n\nbest_acc = 0.\n\nfor epoch in range(1, epochs + 1):\n    print(\"\\n################################################# EPOCH\", epoch)\n    training_loss, training_acc = train(model, epoch)\n    validation_loss, validation_acc = validation(model)\n    \n    training_losses.append(training_loss)\n    training_accs.append(training_acc)\n    validation_losses.append(validation_loss)\n    validation_accs.append(validation_acc)\n    \n    scheduler.step(validation_loss)\n    \n    print('Training set:\\t Average loss: {:.4f}\\t Accuracy: {:.0f}/{:.0f} ({:.0f}%)'.format(\n        training_loss, training_acc*train_size, train_size, training_acc*100))\n    \n    print('Validation set:\\t Average loss: {:.4f}\\t Accuracy: {:.0f}/{:.0f} ({:.0f}%)'.format(\n        validation_loss, validation_acc*val_size, val_size, validation_acc*100))\n    \n    if validation_acc >= best_acc or epoch==epochs:\n        print('\\n**********Saving model with accuracy {:0.4f} at epoch {:2d}'.format(validation_acc, epoch))\n        best_acc = validation_acc\n        model_file = 'experiments' + '/model_' + str(epoch) + '.pth'\n        torch.save(model.state_dict(), model_file)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:33:45.708732Z","iopub.execute_input":"2021-11-22T17:33:45.709573Z","iopub.status.idle":"2021-11-22T17:37:49.900318Z","shell.execute_reply.started":"2021-11-22T17:33:45.709523Z","shell.execute_reply":"2021-11-22T17:37:49.899351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"preds = np.array([])\nmodel.eval()\nwith torch.no_grad():\n    for i, (data, labels) in tqdm(enumerate(test_loader, 18)):\n        data, labels = data.to(device), labels.to(device)\n        output1 = model(data)\n        sm = nn.Softmax(dim=1)(output1)\n        pred = sm.max(1, keepdim=True)[1]    \n        preds = np.hstack((preds, torch.squeeze(pred).cpu().numpy()))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:37:49.902348Z","iopub.execute_input":"2021-11-22T17:37:49.90273Z","iopub.status.idle":"2021-11-22T17:37:56.045822Z","shell.execute_reply.started":"2021-11-22T17:37:49.902691Z","shell.execute_reply":"2021-11-22T17:37:56.044939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(\"submission.csv\", \"w\")\nf.write(\"Id,Category\\n\")\nfor (n,_),p in zip(test_loader.dataset.samples,preds):\n    f.write(\"{},{}\\n\".format(n.split('/')[-1].split('.')[0], int(p)))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T17:37:56.047843Z","iopub.execute_input":"2021-11-22T17:37:56.048116Z","iopub.status.idle":"2021-11-22T17:37:56.063927Z","shell.execute_reply.started":"2021-11-22T17:37:56.04807Z","shell.execute_reply":"2021-11-22T17:37:56.063087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}