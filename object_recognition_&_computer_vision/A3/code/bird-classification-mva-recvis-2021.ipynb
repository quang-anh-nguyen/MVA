{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport torch.nn.functional as F\n\n\nfrom tqdm import tqdm\nimport PIL.Image as Image\n\nif not os.path.isdir('./experiments'):\n    os.makedirs('./experiments')\n    \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T16:47:15.227358Z","iopub.execute_input":"2021-11-20T16:47:15.22799Z","iopub.status.idle":"2021-11-20T16:47:15.236966Z","shell.execute_reply.started":"2021-11-20T16:47:15.22795Z","shell.execute_reply":"2021-11-20T16:47:15.235977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading & Model creation","metadata":{}},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n    transforms.Resize((256, 256), Image.BILINEAR),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((256, 256), Image.BILINEAR),\n    transforms.RandomRotation(15),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize    \n])\n\nvalid_transforms = transforms.Compose([\n    transforms.Resize((256, 256), Image.BILINEAR),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize,\n])\n\nbatch_size = 64\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/mva-recvis-2021/bird_dataset/train_images', transform=train_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/mva-recvis-2021/bird_dataset/val_images',transform=valid_transforms),\n    batch_size=batch_size, shuffle=True, num_workers=1)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder('../input/mva-recvis-2021/bird_dataset/test_images',transform=valid_transforms),\n    batch_size=1, shuffle=False, num_workers=1)\n\ntrain_size, val_size = len(train_loader.dataset), len(val_loader.dataset)\nprint(train_size, val_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:02:58.419719Z","iopub.execute_input":"2021-11-20T18:02:58.420292Z","iopub.status.idle":"2021-11-20T18:02:58.463315Z","shell.execute_reply.started":"2021-11-20T18:02:58.420254Z","shell.execute_reply":"2021-11-20T18:02:58.460478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\n\n\nfor f in os.listdir('experiments/'):\n    os.remove(os.path.join('experiments', f))\n\n\n\nmodel_name = 'resnet152'\n# model_name = 'efficientnet_b7'\n# model_name = 'resnext'\n\nif model_name == 'resnet152':\n    model = torchvision.models.resnet152(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n#     for param in model.layer4.parameters():\n#         param.requires_grad = True\n    # for param in model.fc.parameters():\n    #     param.requires_grad = True   \n    model.fc = nn.Linear(model.fc.in_features, 20)\n\n\nif model_name == 'efficientnet_b7':\n    model = torchvision.models.efficientnet_b7(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.classifier()\n\nif model_name == 'resnext':\n    model = torchvision.models.resnext101_32x8d(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n    model.fc = nn.Linear(model.fc.in_features, 20)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:13:52.533065Z","iopub.execute_input":"2021-11-20T18:13:52.533779Z","iopub.status.idle":"2021-11-20T18:13:54.659909Z","shell.execute_reply.started":"2021-11-20T18:13:52.533744Z","shell.execute_reply":"2021-11-20T18:13:54.659146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for param in model.parameters():\n#     if param.requires_grad:\n#         print(param.size())\n\n# model","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:13:54.661636Z","iopub.execute_input":"2021-11-20T18:13:54.661914Z","iopub.status.idle":"2021-11-20T18:13:54.665929Z","shell.execute_reply.started":"2021-11-20T18:13:54.661879Z","shell.execute_reply":"2021-11-20T18:13:54.664394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5, weight_decay=0.01)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, min_lr=1e-8, patience=10)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:13:54.667211Z","iopub.execute_input":"2021-11-20T18:13:54.667625Z","iopub.status.idle":"2021-11-20T18:13:54.803303Z","shell.execute_reply.started":"2021-11-20T18:13:54.667585Z","shell.execute_reply":"2021-11-20T18:13:54.802477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def train(model, epoch):\n    model.train()\n    training_loss = 0\n    correct = 0\n    \n    for batch_idx, (data, labels) in enumerate(train_loader):\n               \n        data, labels = data.to(device), labels.to(device)\n        optimizer.zero_grad()\n        \n        #forward\n        preds = model(data)\n        loss = criterion(preds, labels)\n        \n        training_loss += loss.data.cpu().item()*len(data)\n        loss.backward()\n        optimizer.step()\n        \n        probs = F.softmax(preds, dim=1)\n        preds_classes = probs.max(1)[1]\n        correct += (preds_classes == labels).sum().data.cpu().detach().item()\n        \n        if batch_idx % 25 == 0:\n            print('[{:4d}/{:4d} ({:2.0f}%)]\\tLoss: {:.4f}'.format(\n                batch_idx * batch_size, train_size,\n                100. * batch_idx * batch_size / train_size, loss.data.cpu().detach().item()))\n    \n    return training_loss / train_size, correct / train_size\n\n\ndef validation(model):\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    \n    with torch.no_grad():\n        for data, labels in val_loader:\n            data, labels = data.to(device), labels.to(device)\n            preds = model(data)\n            \n            # sum up batch loss\n            validation_loss += criterion(preds, labels).data.cpu().detach().item()*len(data)\n            probs = F.softmax(preds, dim=1)\n            preds_classes = probs.max(1)[1]\n            correct += (preds_classes == labels).sum().data.cpu().detach().item()\n            \n    return validation_loss / val_size, correct / val_size","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:13:54.805156Z","iopub.execute_input":"2021-11-20T18:13:54.805415Z","iopub.status.idle":"2021-11-20T18:13:54.819532Z","shell.execute_reply.started":"2021-11-20T18:13:54.805378Z","shell.execute_reply":"2021-11-20T18:13:54.818557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 25\ntraining_losses = []\ntraining_accs = []\nvalidation_losses = []\nvalidation_accs = []\n\nbest_acc = 0.\n\nfor epoch in range(1, epochs + 1):\n    print(\"\\n################################################# EPOCH\", epoch)\n    training_loss, training_acc = train(model, epoch)\n    validation_loss, validation_acc = validation(model)\n    \n    training_losses.append(training_loss)\n    training_accs.append(training_acc)\n    validation_losses.append(validation_loss)\n    validation_accs.append(validation_acc)\n    \n    scheduler.step(validation_loss)\n    \n    print('Training set:\\t Average loss: {:.4f}\\t Accuracy: {:.0f}/{:.0f} ({:.0f}%)'.format(\n        training_loss, training_acc*train_size, train_size, training_acc*100))\n    \n    print('Validation set:\\t Average loss: {:.4f}\\t Accuracy: {:.0f}/{:.0f} ({:.0f}%)'.format(\n        validation_loss, validation_acc*val_size, val_size, validation_acc*100))\n    \n    if validation_acc >= best_acc or epoch==epochs:\n        print('\\n**********Saving model with accuracy {:0.4f} at epoch {:2d}'.format(validation_acc, epoch))\n        best_acc = validation_acc\n        model_file = 'experiments' + '/model_' + str(epoch) + '.pth'\n        torch.save(model.state_dict(), model_file)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:13:56.019527Z","iopub.execute_input":"2021-11-20T18:13:56.020399Z","iopub.status.idle":"2021-11-20T18:19:50.673824Z","shell.execute_reply.started":"2021-11-20T18:13:56.020345Z","shell.execute_reply":"2021-11-20T18:19:50.672958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12.8, 6.4))\nits = np.arange(0, epochs)\nplt.plot(its, training_losses[its[0]:], label='train')\nplt.plot(its, validation_losses[its[0]:], label='valid')\nplt.legend(loc=2)\n\nplt.sca(plt.gca().twinx())\nplt.plot(its, training_accs[its[0]:], '--', label='train acc')\nplt.plot(its, validation_accs[its[0]:], '--', label='valid acc')\n\nplt.title(model_name)\nplt.legend(loc=7)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:09:45.160642Z","iopub.execute_input":"2021-11-20T18:09:45.161407Z","iopub.status.idle":"2021-11-20T18:09:45.480195Z","shell.execute_reply.started":"2021-11-20T18:09:45.161366Z","shell.execute_reply":"2021-11-20T18:09:45.479549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmin(validation_losses), np.argmax(validation_accs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"preds = np.array([])\n\nmodel.load_state_dict(torch.load('experiments/model_' + str(25) + '.pth'))\n\nmodel.eval()\nwith torch.no_grad():\n    for i, (data, labels) in tqdm(enumerate(test_loader, 0)):\n        data, labels = data.to(device), labels.to(device)\n        output1 = model(data)\n        sm = nn.Softmax(dim=1)(output1)\n        pred = sm.max(1, keepdim=True)[1]    \n        preds = np.hstack((preds, torch.squeeze(pred).cpu().numpy()))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:10:13.417873Z","iopub.execute_input":"2021-11-20T18:10:13.418446Z","iopub.status.idle":"2021-11-20T18:10:28.961712Z","shell.execute_reply.started":"2021-11-20T18:10:13.418395Z","shell.execute_reply":"2021-11-20T18:10:28.96088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(\"submission.csv\", \"w\")\nf.write(\"Id,Category\\n\")\nfor (n,_),p in zip(test_loader.dataset.samples,preds):\n    f.write(\"{},{}\\n\".format(n.split('/')[-1].split('.')[0], int(p)))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T18:10:34.729656Z","iopub.execute_input":"2021-11-20T18:10:34.730253Z","iopub.status.idle":"2021-11-20T18:10:34.738449Z","shell.execute_reply.started":"2021-11-20T18:10:34.730218Z","shell.execute_reply":"2021-11-20T18:10:34.737385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}